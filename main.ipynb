{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8dfb43",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from model import MultimodalDeepfakeDetector\n",
    "from preprocessor import VideoAudioProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39450dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    \"\"\"Evaluate the deepfake detection model on test data\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for style_features, content_features, audio_features, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "            # Move data to device\n",
    "            style_features = style_features.to(device)\n",
    "            content_features = content_features.to(device)\n",
    "            audio_features = audio_features.to(device) if audio_features is not None else None\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            final_pred, _, _ = model(style_features, content_features, audio_features)\n",
    "            \n",
    "            # Store predictions and labels\n",
    "            all_preds.extend(final_pred.cpu().numpy().flatten())\n",
    "            all_labels.extend(labels.cpu().numpy().flatten())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = np.mean((all_preds > 0.5) == all_labels)\n",
    "    \n",
    "    # Calculate AUC-ROC if sklearn is available\n",
    "    try:\n",
    "        from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score\n",
    "        \n",
    "        auc_roc = roc_auc_score(all_labels, all_preds)\n",
    "        average_precision = average_precision_score(all_labels, all_preds)\n",
    "        \n",
    "        # Calculate precision, recall, and thresholds\n",
    "        precision, recall, thresholds = precision_recall_curve(all_labels, all_preds)\n",
    "        \n",
    "        # Find the threshold that gives the best F1 score\n",
    "        f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "        best_idx = np.argmax(f1_scores)\n",
    "        best_threshold = thresholds[best_idx] if best_idx < len(thresholds) else 0.5\n",
    "        \n",
    "        print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "        print(f\"Average Precision: {average_precision:.4f}\")\n",
    "        print(f\"Best Threshold: {best_threshold:.4f}\")\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'auc_roc': auc_roc,\n",
    "            'average_precision': average_precision,\n",
    "            'best_threshold': best_threshold\n",
    "        }\n",
    "    \n",
    "    except ImportError:\n",
    "        print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "        return {'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32535ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_video_predictions(predictions, sample_to_video, video_counts):\n",
    "    \"\"\"Merge predictions from multiple clips of the same video\"\"\"\n",
    "    video_predictions = {}\n",
    "    \n",
    "    for pred, video_id in zip(predictions, sample_to_video):\n",
    "        if video_id not in video_predictions:\n",
    "            video_predictions[video_id] = []\n",
    "        \n",
    "        video_predictions[video_id].append(pred)\n",
    "    \n",
    "    # Average predictions for each video\n",
    "    final_predictions = {}\n",
    "    for video_id, preds in video_predictions.items():\n",
    "        final_predictions[video_id] = sum(preds) / len(preds)\n",
    "    \n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155d1bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Example usage\n",
    "    processor = VideoAudioProcessor(\n",
    "        output_dir='processed_data',\n",
    "        frame_rate=1,\n",
    "        face_confidence=0.5,\n",
    "        audio_sample_rate=16000,\n",
    "        style_gru_model_path='external/StyleFlow/model.pth',\n",
    "        style_feature_size=9216,\n",
    "        sequence_length=32\n",
    "    )\n",
    "    \n",
    "    # Process a dataset\n",
    "    label_map = {\n",
    "        'real': 0,\n",
    "        'fake': 1,\n",
    "        'deepfake': 1,\n",
    "        'faceswap': 1\n",
    "    }\n",
    "    \n",
    "    # Process dataset and prepare features\n",
    "    results = processor.process_dataset('path/to/videos', label_map)\n",
    "    prepared_data = processor.prepare_for_stylegru(results, 'processed_data/prepared_data.pkl')\n",
    "    \n",
    "    # Create model\n",
    "    model = MultimodalDeepfakeDetector(\n",
    "        style_dim=8192,\n",
    "        content_dim=512,\n",
    "        fusion_dim=1024,\n",
    "        audio_dim=120,\n",
    "        transformer_dim=512,\n",
    "        num_heads=8,\n",
    "        num_layers=4,\n",
    "        sequence_length=16\n",
    "    )\n",
    "    \n",
    "    # Create data loaders (this would need to be implemented based on your data format)\n",
    "    # train_loader, val_loader, test_loader = create_data_loaders(prepared_data)\n",
    "    \n",
    "    # Train model\n",
    "    # trained_model = train_model(model, train_loader, val_loader, num_epochs=10)\n",
    "    \n",
    "    # Evaluate model\n",
    "    # metrics = evaluate_model(trained_model, test_loader)\n",
    "    \n",
    "    # Make prediction on a single video\n",
    "    # result = model.predict_video('path/to/test_video.mp4', processor)\n",
    "    # print(f\"Prediction: {result['final_prediction']:.4f}, Is Fake: {result['is_fake']}\")\n",
    "    \n",
    "    print(\"Processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd3504b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
